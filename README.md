<b> ðŸ§  Project Title </b>
</br>
On-Device Speech-to-Text Model for Low-Latency Applications 

<b> ðŸ‘¥ Team Details </b>
</br>
Team Name: text2talk
</br>
Member 1: Niharika (niharika10092005@gmail.com)
</br>
Member 2: Avantika Panday (Er.avantikapandey@gmail.com)
</br>
Member 3: Gaytri Mehta (gayatri.mehta.au@gmail.com)
</br>
Member 4: Kashvi Sharma (kashvi.sharma5944@gmail.com)
</br>
Member 5: Komalpreet Kaur (@gmail.com)

<b> ðŸ§© Problem Statement  </b>
</br>
While speech-to-text (STT) systems are becoming increasingly popular in applications like voice assistants, note-taking tools and accessibility platforms, most current solutions are cloud-dependent, requiring stable internet access and transmitting user data to remote servers. This approach introduces latency issues, privacy risks and limited usability in offline or low-connectivity environmentsâ€”especially problematic in academic institutions, rural areas, or for users with special accessibility needs.
In contexts like Panjab University, where students and staff may work in offline settings or constrained digital environments, there's a critical need for a fast, reliable, and privacy-respecting speech-to-text system that can run directly on local devices such as laptops.

<b> ðŸš€ Motivation  </b>
</br>
In todayâ€™s digital age, speech-to-text (STT) technology has revolutionized the way we interact with devicesâ€”making tasks like note-taking, content creation, and communication faster and more intuitive. Yet, most popular STT tools rely heavily on internet connectivity and send audio data to external servers. This not only raises privacy and security concerns but also creates delays and increases dependency on costly infrastructureâ€”especially in environments like universities.
At Panjab University, where students come from varied backgrounds and regions, this becomes a real challenge. Learners in remote areas or with limited access to high-end devices often struggle with cloud-based tools. For visually impaired or motor-disabled usersâ€”those who could benefit the most from voice-powered systemsâ€”these limitations mean exclusion rather than empowerment.
Thatâ€™s where our project steps in.
We're developing an offline, voice-editable STT solution that is lightweight, open-source, and privacy-conscious. Our goal is to provide a tool that works anytime, anywhereâ€”without relying on internet access. With built-in voice command support, users will be able to dictate, edit, and format text using just their voice.
This innovation isnâ€™t just about performanceâ€”itâ€™s about inclusion. Whether you're a content creator, a person with physical disabilities, or someone striving for hands-free productivity, our solution is designed to make digital expression easier, more accessible, and truly empowering.

<b> ðŸŽ¯ Expected Outcome  </b>
</br>
Real-Time Speech-to-Text Conversion
Model Comparison & Benchmarking
Offline-First Functionality
Custom Use-Case Adaptation

<b> ðŸ“… Timeline & Milestones  </b>
</br>
Week 1: Research & Setup 
Week 2: Preprocessing & Initial Integration
Week 3: Feature Expansion
Week 4: Evaluation and Optimization
Week 5: Finalization & Submission

<b> ðŸ“¦ Final Deliverables  </b>
</br>
Model benchmarks (latency, accuracy, resource usage)
A responsive web interface
A note summarization module
Comprehensive documentation

<b> ðŸ“Ž Appendix (Optional) </b>
No response
